{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai\n",
    "import configparser\n",
    "import ast\n",
    "import re \n",
    "import time\n",
    "from  scipy.special import expit, logit\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "import backoff\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "api_key = config.get('Keys','openai_api_key')\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def completions_with_backoff(**kwargs):\n",
    "    return openai.Completion.create(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCI1_W34</td>\n",
       "      <td>Overall, do you think science has made life ea...</td>\n",
       "      <td>['Easier', 'More difficult', 'Refused']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCI2A_W34</td>\n",
       "      <td>Do you think science has had a mostly positive...</td>\n",
       "      <td>['Mostly positive', 'Mostly negative', 'Refused']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCI2B_W34</td>\n",
       "      <td>Do you think science has had a mostly positive...</td>\n",
       "      <td>['Mostly positive', 'Mostly negative', 'Refused']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCI2C_W34</td>\n",
       "      <td>Do you think science has had a mostly positive...</td>\n",
       "      <td>['Mostly positive', 'Mostly negative', 'Refused']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCI3A_W34</td>\n",
       "      <td>In your opinion, do you think government inves...</td>\n",
       "      <td>['Government investments usually pay off in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>EVOBIOA_W34</td>\n",
       "      <td>From what you have heard or read, which of the...</td>\n",
       "      <td>['Humans have evolved over time due to process...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>EVOBIOB_W34</td>\n",
       "      <td>Even if you are not sure, from what you have h...</td>\n",
       "      <td>['Humans have evolved over time due to process...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>BIO15_W34</td>\n",
       "      <td>Have you seen a health care provider for an il...</td>\n",
       "      <td>['Yes', 'No', 'Refused']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>G1_W34</td>\n",
       "      <td>Do you, or does anyone in your immediate famil...</td>\n",
       "      <td>['Yes', 'No', 'Not sure', 'Refused']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>G2_W34</td>\n",
       "      <td>Have you, or has anyone in your immediate fami...</td>\n",
       "      <td>['Yes', 'No', 'Not sure', 'Refused']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key                                           question  \\\n",
       "0      SCI1_W34  Overall, do you think science has made life ea...   \n",
       "1     SCI2A_W34  Do you think science has had a mostly positive...   \n",
       "2     SCI2B_W34  Do you think science has had a mostly positive...   \n",
       "3     SCI2C_W34  Do you think science has had a mostly positive...   \n",
       "4     SCI3A_W34  In your opinion, do you think government inves...   \n",
       "..          ...                                                ...   \n",
       "62  EVOBIOA_W34  From what you have heard or read, which of the...   \n",
       "63  EVOBIOB_W34  Even if you are not sure, from what you have h...   \n",
       "64    BIO15_W34  Have you seen a health care provider for an il...   \n",
       "65       G1_W34  Do you, or does anyone in your immediate famil...   \n",
       "66       G2_W34  Have you, or has anyone in your immediate fami...   \n",
       "\n",
       "                                              options  \n",
       "0             ['Easier', 'More difficult', 'Refused']  \n",
       "1   ['Mostly positive', 'Mostly negative', 'Refused']  \n",
       "2   ['Mostly positive', 'Mostly negative', 'Refused']  \n",
       "3   ['Mostly positive', 'Mostly negative', 'Refused']  \n",
       "4   ['Government investments usually pay off in th...  \n",
       "..                                                ...  \n",
       "62  ['Humans have evolved over time due to process...  \n",
       "63  ['Humans have evolved over time due to process...  \n",
       "64                           ['Yes', 'No', 'Refused']  \n",
       "65               ['Yes', 'No', 'Not sure', 'Refused']  \n",
       "66               ['Yes', 'No', 'Not sure', 'Refused']  \n",
       "\n",
       "[67 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfi = pd.read_table(\"data/model_input/Pew_American_Trends_Panel_W34.csv\")\n",
    "dfi = dfi[[\"key\", \"question\", \"options\"]]\n",
    "\n",
    "dfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How often do you choose foods to eat because they are easy and most convenient?\n",
      "\n",
      " A. All of the time\n",
      " B. More than half of the time\n",
      " C. About half of the time\n",
      " D. Less than half of the time\n",
      " E. Never\n",
      "\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "def make_survey_item(question, resp_list, answer=\"\"):\n",
    "    q = question + \"\\n\\n\"\n",
    "\n",
    "    r_options = \"\\n\".join([\" \" + r for r in resp_list])\n",
    "    suffix = \"\\n\\nAnswer:\"\n",
    "    if len(answer) > 0:\n",
    "        suffix += \" \" + answer\n",
    "\n",
    "    return(make_prompt(r_options, q, suffix))\n",
    "\n",
    "\n",
    "def make_survey_item_df(row, ans=\"\"):\n",
    "    q = row[\"question\"]\n",
    "    r_list = ast.literal_eval(row[\"options\"])\n",
    "    \n",
    "    if \"Refused\" in r_list:\n",
    "        r_list.remove(\"Refused\")\n",
    "\n",
    "    r_list = [\". \".join(x) for x in zip([\"A\",\"B\",\"C\",\"D\",\"E\"], r_list)]\n",
    "\n",
    "    return(make_survey_item(q, r_list, ans))\n",
    "\n",
    "\n",
    "def make_survey_df(row):\n",
    "    r_list = ast.literal_eval(row[\"options\"])\n",
    "    \n",
    "    if \"Refused\" in r_list:\n",
    "        r_list.remove(\"Refused\")\n",
    "\n",
    "    ans_list = [\"A\",\"B\",\"C\",\"D\",\"E\"][:len(r_list)]\n",
    "\n",
    "    out_list = [make_survey_item_df(row, x) for x in ans_list]\n",
    "\n",
    "    return(out_list)\n",
    "\n",
    "test_q = make_survey_item_df(dfi.iloc[10])\n",
    "\n",
    "print(test_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How often do you choose foods to eat because they are easy and most convenient?\\n\\n A. All of the time\\n B. More than half of the time\\n C. About half of the time\\n D. Less than half of the time\\n E. Never\\n\\nAnswer: A',\n",
       " 'How often do you choose foods to eat because they are easy and most convenient?\\n\\n A. All of the time\\n B. More than half of the time\\n C. About half of the time\\n D. Less than half of the time\\n E. Never\\n\\nAnswer: B',\n",
       " 'How often do you choose foods to eat because they are easy and most convenient?\\n\\n A. All of the time\\n B. More than half of the time\\n C. About half of the time\\n D. Less than half of the time\\n E. Never\\n\\nAnswer: C',\n",
       " 'How often do you choose foods to eat because they are easy and most convenient?\\n\\n A. All of the time\\n B. More than half of the time\\n C. About half of the time\\n D. Less than half of the time\\n E. Never\\n\\nAnswer: D',\n",
       " 'How often do you choose foods to eat because they are easy and most convenient?\\n\\n A. All of the time\\n B. More than half of the time\\n C. About half of the time\\n D. Less than half of the time\\n E. Never\\n\\nAnswer: E']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_qs = make_survey_df(dfi.iloc[10])\n",
    "test_qs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt = test_q,\n",
    "        logprobs=1,\n",
    "        echo=True,\n",
    "        max_tokens=0\n",
    "    )\n",
    "\n",
    "# # responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.7166117 ,  -0.21475565,  -8.52491   , -12.513472  ,\n",
       "       -20.809069  ])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_survey_logprobs(responses):\n",
    "    logprobs = get_gpt_logprobs(responses)\n",
    "    return(np.array([x[-1] for x in logprobs]))\n",
    "\n",
    "get_survey_logprobs(responses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_survey_responses(row, model = \"text-davinci-003\", sleep = 0):\n",
    "    qs = make_survey_df(row)\n",
    "\n",
    "    # sleep for sleep seconds (default = 0)\n",
    "    time.sleep(sleep)\n",
    "\n",
    "    responses = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt = qs,\n",
    "        logprobs=1,\n",
    "        echo=True,\n",
    "        max_tokens=0,\n",
    "        temperature = 0\n",
    "    )\n",
    "\n",
    "    logprobs = get_survey_logprobs(responses)\n",
    "\n",
    "    return(logprobs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>EAT5C_W34</td>\n",
       "      <td>How much health risk, if any, does eating food...</td>\n",
       "      <td>['A great deal of health risk', 'Some health r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EAT5D_W34</td>\n",
       "      <td>How much health risk, if any, does eating food...</td>\n",
       "      <td>['A great deal of health risk', 'Some health r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EAT6_W34</td>\n",
       "      <td>Which of these statements comes closer to your...</td>\n",
       "      <td>['The average person is exposed to additives i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          key                                           question  \\\n",
       "22  EAT5C_W34  How much health risk, if any, does eating food...   \n",
       "23  EAT5D_W34  How much health risk, if any, does eating food...   \n",
       "24   EAT6_W34  Which of these statements comes closer to your...   \n",
       "\n",
       "                                              options  \n",
       "22  ['A great deal of health risk', 'Some health r...  \n",
       "23  ['A great deal of health risk', 'Some health r...  \n",
       "24  ['The average person is exposed to additives i...  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = dfi[22:25]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dfi.assign(logprobs = dfi.apply(gpt_survey_responses, axis=1, sleep=1.))\n",
    "df_gpt = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompting with other questions\n",
    "\n",
    "67 questions x up to 5 answer choices x 67 preceding questions for context = lots of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "prompts = []\n",
    "prompt_answers = []\n",
    "\n",
    "total_tokens = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        if j!=i:\n",
    "            # row = df.iloc[i]\n",
    "            qs = make_survey_df(df.iloc[i]) # question i with each possible answer\n",
    "            ps = make_survey_df(df.iloc[j]) # prompts with each answer for question j\n",
    "            for p in ps:\n",
    "                for q in qs:\n",
    "                    prompts.append(p)\n",
    "                    questions.append(p + \"\\n\\n\" + q)\n",
    "                    total_tokens += count_tokens(p + \"\\n\\n\" + q)\n",
    "\n",
    "\n",
    "            # tokens = sum([count_tokens(p) for p in qs])\n",
    "                \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4489\n",
      "total tokens 943232\n",
      "$ 18.86464\n"
     ]
    }
   ],
   "source": [
    "print(67*67)\n",
    "print(\"total tokens\", total_tokens)\n",
    "print(\"$\", total_tokens/1000*.02)\n",
    "# print(questions[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.76200237350308"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens/len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resp_dict(df, item):\n",
    "    df = df[df[\"key\"] == item]\n",
    "    df.reset_index(inplace=True)\n",
    "    string = df[\"option_mapping\"][0]\n",
    "    a = ast.literal_eval(string)\n",
    "    res = dict((v,k) for k,v in a.items())\n",
    "\n",
    "    return(res)\n",
    "\n",
    "\n",
    "info_df = pd.read_csv(\"data/human_resp/American_Trends_Panel_W34/info.csv\")\n",
    "key_vars = info_df.key.to_list()\n",
    "\n",
    "df = pd.read_csv(\"data/human_resp/American_Trends_Panel_W34/responses.csv\")\n",
    "df = df[key_vars]\n",
    "\n",
    "for c in df.columns:\n",
    "    rdict = get_resp_dict(info_df, c)\n",
    "    df[c] = df[c].map(rdict)\n",
    "\n",
    "df_long = pd.melt(df.reset_index(), id_vars='index')\n",
    "\n",
    "corrmat = df.replace(99.0, np.NaN).corr() # drop missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_var</th>\n",
       "      <th>prompt_var</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCI1_W34</td>\n",
       "      <td>SCI3B_W34</td>\n",
       "      <td>0.195653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCI1_W34</td>\n",
       "      <td>SCI2A_W34</td>\n",
       "      <td>0.235727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCI1_W34</td>\n",
       "      <td>SCI3A_W34</td>\n",
       "      <td>0.254028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCI1_W34</td>\n",
       "      <td>SCI2C_W34</td>\n",
       "      <td>0.258629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCI1_W34</td>\n",
       "      <td>SCI2B_W34</td>\n",
       "      <td>0.314973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>G2_W34</td>\n",
       "      <td>FUD37D_W34</td>\n",
       "      <td>0.006716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>G2_W34</td>\n",
       "      <td>MED7_W34</td>\n",
       "      <td>0.019071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>G2_W34</td>\n",
       "      <td>MED5_W34</td>\n",
       "      <td>-0.019928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>G2_W34</td>\n",
       "      <td>EAT3J_W34</td>\n",
       "      <td>0.037297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>G2_W34</td>\n",
       "      <td>EAT5D_W34</td>\n",
       "      <td>0.031081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1005 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_var  prompt_var      corr\n",
       "0     SCI1_W34   SCI3B_W34  0.195653\n",
       "1     SCI1_W34   SCI2A_W34  0.235727\n",
       "2     SCI1_W34   SCI3A_W34  0.254028\n",
       "3     SCI1_W34   SCI2C_W34  0.258629\n",
       "4     SCI1_W34   SCI2B_W34  0.314973\n",
       "...        ...         ...       ...\n",
       "1000    G2_W34  FUD37D_W34  0.006716\n",
       "1001    G2_W34    MED7_W34  0.019071\n",
       "1002    G2_W34    MED5_W34 -0.019928\n",
       "1003    G2_W34   EAT3J_W34  0.037297\n",
       "1004    G2_W34   EAT5D_W34  0.031081\n",
       "\n",
       "[1005 rows x 3 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### combine variables pairwise according to correlations to examine influences\n",
    "\n",
    "qvar = []\n",
    "pvar = []\n",
    "corrval = []\n",
    "\n",
    "# for every column in corr matrix\n",
    "for c in corrmat.columns:\n",
    "    corrs = corrmat[c].sort_values()\n",
    "    # find 10 strongest pos and neg correlations\n",
    "    neg = corrs[:5]\n",
    "    pos = corrs[-6:-1]\n",
    "    # and 10 random others\n",
    "    rand = corrs[5:-6].sample(n=5)\n",
    "\n",
    "# and then concat combinations of names, plus corr values\n",
    "    out = pd.concat([pos, neg, rand])\n",
    "    corrval.extend(out.to_list())\n",
    "    pvar.extend(out.index.to_list())\n",
    "    qvar.extend([c]*5*3)\n",
    "\n",
    "df2 = pd.DataFrame({\"query_var\":var1, \"prompt_var\":var2, \"corr\":corrval})\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvar = []\n",
    "pvar = []\n",
    "pvar_ans = []\n",
    "corrval = []\n",
    "\n",
    "for i, row in df2.iterrows():\n",
    "    # dfi.loc[lambda _: _.key==\"SCI1_W34\"].reset_index().loc[0][\"options\"]\n",
    "    r_list = dfi.loc[lambda _: _.key==row[\"prompt_var\"]].reset_index().loc[0][\"options\"]\n",
    "    r_list = ast.literal_eval(r_list)\n",
    "    if \"Refused\" in r_list:\n",
    "        r_list.remove(\"Refused\")\n",
    "\n",
    "    ans_list = [\"A\",\"B\",\"C\",\"D\",\"E\"][:len(r_list)]\n",
    "    n_resps = len(ans_list)\n",
    "\n",
    "    pvar.extend([row[\"prompt_var\"]] * n_resps )\n",
    "    qvar.extend([row[\"query_var\"]] * n_resps )\n",
    "    corrval.extend([row[\"corr\"]] * n_resps )\n",
    "    pvar_ans.extend(ans_list)\n",
    "\n",
    "df3 = pd.DataFrame({\"query_var\":qvar, \"prompt_var\":pvar, \"corr\":corrval, \"prompt_ans\":pvar_ans})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_var</th>\n",
       "      <th>prompt_var</th>\n",
       "      <th>corr</th>\n",
       "      <th>prompt_ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCI1_W34</td>\n",
       "      <td>SCI3B_W34</td>\n",
       "      <td>0.195653</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCI1_W34</td>\n",
       "      <td>SCI3B_W34</td>\n",
       "      <td>0.195653</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCI1_W34</td>\n",
       "      <td>SCI2A_W34</td>\n",
       "      <td>0.235727</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCI1_W34</td>\n",
       "      <td>SCI2A_W34</td>\n",
       "      <td>0.235727</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCI1_W34</td>\n",
       "      <td>SCI3A_W34</td>\n",
       "      <td>0.254028</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>G2_W34</td>\n",
       "      <td>EAT3J_W34</td>\n",
       "      <td>0.037297</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>G2_W34</td>\n",
       "      <td>EAT5D_W34</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>G2_W34</td>\n",
       "      <td>EAT5D_W34</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>G2_W34</td>\n",
       "      <td>EAT5D_W34</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>G2_W34</td>\n",
       "      <td>EAT5D_W34</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2965 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_var prompt_var      corr prompt_ans\n",
       "0     SCI1_W34  SCI3B_W34  0.195653          A\n",
       "1     SCI1_W34  SCI3B_W34  0.195653          B\n",
       "2     SCI1_W34  SCI2A_W34  0.235727          A\n",
       "3     SCI1_W34  SCI2A_W34  0.235727          B\n",
       "4     SCI1_W34  SCI3A_W34  0.254028          A\n",
       "...        ...        ...       ...        ...\n",
       "2960    G2_W34  EAT3J_W34  0.037297          B\n",
       "2961    G2_W34  EAT5D_W34  0.031081          A\n",
       "2962    G2_W34  EAT5D_W34  0.031081          B\n",
       "2963    G2_W34  EAT5D_W34  0.031081          C\n",
       "2964    G2_W34  EAT5D_W34  0.031081          D\n",
       "\n",
       "[2965 rows x 4 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
